{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Montecarlo and TD methods\n",
    "\n",
    "Let's implement these methods for a simple toy case with discrete and action spaces.\n",
    "\n",
    "- Implement First-visit Montecarlo for Frozen lake (1p)\n",
    "- Implement Sarsa and Q-Learning for (1p each)\n",
    "- How does the value function V look for the different Q functions you found above? You can look at tutorial 3 for ideas how to do this plot. (1p) \n",
    "\n",
    "The code below can help you get started with TD. For inspiration about Montecarlo, look at tutorial 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\n",
    "\n",
    "\n",
    "SFFF       (S: starting point, safe)\n",
    "FHFH       (F: frozen surface, safe)\n",
    "FFFH       (H: hole, fall to your doom)\n",
    "HFFG       (G: goal, where the frisbee is located)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states = 16\n",
      "Number of actions = 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of states =\", env.observation_space.n)\n",
    "print(\"Number of actions =\", env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Q, epsilon, actions):\n",
    "    \"\"\" \n",
    "    Q is a numpy array = qualities of (state, action) pairs, \n",
    "    epsilon = prob to choose random action\n",
    "    1 - eps = prob to choose the action with best Q value = argmax(Q[s][:])\n",
    "    actions = list of actions\n",
    "    \"\"\"\n",
    "    \n",
    "    def policy_fn(state):\n",
    "        if np.random.rand()>epsilon:\n",
    "            if np.max(Q[state][:]) == 0:\n",
    "                action = np.random.choice(actions)\n",
    "            else:\n",
    "                action = np.argmax(Q[state][:])\n",
    "        else:\n",
    "            action = np.random.choice(actions)\n",
    "        return action\n",
    "    \n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-visit Montecarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4630.49it/s]\n"
     ]
    }
   ],
   "source": [
    "def run_episode(env, policy): \n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    episode = []\n",
    "    while not done:\n",
    "        action = policy(state)\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        episode.append((state,action,reward))\n",
    "        state = new_state    \n",
    "    return episode # returns list of (state,action,reward)\n",
    "\n",
    "n_iter = 10000\n",
    "gamma = 0.99 # discount factor\n",
    "total_episode_rewards = []\n",
    "\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n]) # Q function\n",
    "R = defaultdict(lambda: np.zeros(env.action_space.n)) # Sum of first-visit rewards of a certain (state, action)\n",
    "N = defaultdict(lambda: np.zeros(env.action_space.n)) # Number of first-visits of a certain (state, action)\n",
    "actions = range(env.action_space.n)\n",
    "\n",
    "for j in tqdm(range(n_iter)):\n",
    "    # Play 100 episodes randomly, then slowly reduce the randomness\n",
    "    policy = epsilon_greedy_policy(Q, epsilon=100./(j+1), actions = actions ) \n",
    "    \n",
    "    episode = run_episode(env, policy) # run till losing\n",
    "    \n",
    "    ep_reward = sum(x[2]*(gamma**i) for i, x in enumerate(episode)) # episode = list of (state,action,reward)\n",
    "    #if ep_reward > 0:\n",
    "    #    print(j, \"reward =\", ep_reward, \"episode=\", episode)\n",
    "    total_episode_rewards.append(ep_reward) # only for logging\n",
    "    \n",
    "    # each move in a episode is converted to a tuple of (state, action) to use as dict key\n",
    "    sa_in_episode = set([(x[0],x[1]) for x in episode]) \n",
    "    \n",
    "    # Find first visit of each (state,action) in the episode\n",
    "    for s,a in sa_in_episode:\n",
    "        first_visit = next(i for i,x in enumerate(episode) if x[0]==s and x[1]==a)\n",
    "        \n",
    "        G = sum(x[2]*(gamma**i) for i, x in enumerate(episode[first_visit:])) # calc reward from this (s,a) till the end of the episode\n",
    "        \n",
    "        R[s][a] += G\n",
    "        N[s][a] += 1\n",
    "        Q[s][a] += R[s][a]/N[s][a] # update Q-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(range(16))\n",
    "arr.reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q =\n",
      " [[8.49042506e+00 5.53557835e+02 3.57076677e+00 5.38038700e+00]\n",
      " [6.70830213e-01 2.31774160e+02 2.28285155e+00 2.61740932e+00]\n",
      " [1.93833822e+02 2.02316375e+00 1.41971799e+00 1.32529349e+00]\n",
      " [0.00000000e+00 2.15323396e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.90400085e+00 4.11627925e+02 1.03955934e+00 2.31312623e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.46335826e+00 3.37065424e+00 2.21488991e+02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.54748983e-01 4.26108892e+02 2.56800008e+00 2.66573424e+00]\n",
      " [2.52746602e+00 3.46156425e+00 4.97976708e+02 4.14104417e+00]\n",
      " [4.28059950e+02 4.83739200e+00 4.39541188e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.66110676e+00 5.33849473e+00 3.98393241e+02 7.37811872e-01]\n",
      " [3.95840300e+00 6.50215233e+02 8.27120711e+00 2.30918329e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Q argmax =\n",
      " [1 1 0 1 1 0 2 0 1 2 0 0 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q =\\n\", Q)\n",
    "print(\"Q argmax =\\n\", np.argmax(Q, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.argmax(Q, axis=1).reshape(4,4), cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(\"Best action to take in each state.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-03-06 08:21:11,952] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "actions = range(env.action_space.n)\n",
    "score = [] \n",
    "\n",
    "gamma = 0.99 # discount factor\n",
    "alpha = 0.1  # \n",
    "n_episodes = 100\n",
    " \n",
    "for j in range(n_episodes):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    \n",
    "    # Play randomly 10 episodes, then reduce slowly the randomness\n",
    "    policy = epsilon_greedy_policy(Q, epsilon=10./(j+1), actions = actions ) \n",
    "    \n",
    "    \n",
    "    ### Generate sample episode\n",
    "    t=0\n",
    "    while not done:\n",
    "        t+=1\n",
    "        action = policy(state)    \n",
    "        new_state, reward, done, _ =  env.step(action)\n",
    "        new_action = policy(new_state)\n",
    "        \n",
    "        #Book-keeping\n",
    "        if done:\n",
    "            # YOUR CODE GOES HERE\n",
    "            pass\n",
    "        else:\n",
    "            # YOUR CODE GOES HERE\n",
    "            pass\n",
    "            \n",
    "        state, action = new_state, new_action\n",
    "            \n",
    "        if done:\n",
    "            if len(score) < 100:\n",
    "                score.append(reward)\n",
    "            else:\n",
    "                score[j % 100] = reward\n",
    "                \n",
    "                \n",
    "            if (j+1)%1000 == 0:\n",
    "                print(\"INFO: Episode {} finished after {} timesteps with r={}. \\\n",
    "                Running score: {}\".format(j+1, t, reward, np.mean(score)))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
